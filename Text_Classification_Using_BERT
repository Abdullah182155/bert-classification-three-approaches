{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abdullah182/text-classification-using-bert?scriptVersionId=284929531\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install transformers datasets torch gradio \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:22:18.230293Z","iopub.execute_input":"2025-12-09T12:22:18.230852Z","iopub.status.idle":"2025-12-09T12:23:33.705558Z","shell.execute_reply.started":"2025-12-09T12:22:18.230816Z","shell.execute_reply":"2025-12-09T12:23:33.704731Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.3)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nCollecting pydantic<2.12,>=2.0 (from gradio)\n  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nCollecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pydantic-core, pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.41.5\n    Uninstalling pydantic_core-2.41.5:\n      Successfully uninstalled pydantic_core-2.41.5\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.12.4\n    Uninstalling pydantic-2.12.4:\n      Successfully uninstalled pydantic-2.12.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0 pydantic-2.11.10 pydantic-core-2.33.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import Libraries\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"✓ All libraries imported successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:23:33.706989Z","iopub.execute_input":"2025-12-09T12:23:33.707224Z","iopub.status.idle":"2025-12-09T12:23:46.809216Z","shell.execute_reply.started":"2025-12-09T12:23:33.7072Z","shell.execute_reply":"2025-12-09T12:23:46.808562Z"}},"outputs":[{"name":"stdout","text":"✓ All libraries imported successfully\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load the auditor review dataset\ndataset = load_dataset(\"rajistics/auditor_review\")\n\n# Convert to pandas for easier manipulation\ndf = pd.DataFrame(dataset['train'])\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nColumn names:\")\nprint(df.columns.tolist())\nprint(\"\\nLabel distribution:\")\nprint(df['label'].value_counts())\n\n# Map text labels to numeric if needed\nunique_labels = df['label'].unique()\nlabel_map = {label: idx for idx, label in enumerate(sorted(unique_labels))}\nreverse_label_map = {idx: label for label, idx in label_map.items()}\ndf['label_numeric'] = df['label'].map(label_map)\n\nprint(\"\\nLabel mapping:\")\nprint(reverse_label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:23:46.809902Z","iopub.execute_input":"2025-12-09T12:23:46.810333Z","iopub.status.idle":"2025-12-09T12:23:52.147221Z","shell.execute_reply.started":"2025-12-09T12:23:46.810312Z","shell.execute_reply":"2025-12-09T12:23:52.14652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4068b92ae0fd4f5bab01fdfb4f769e9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/801 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b9f696ee6a4eaf8efa2b01a31ca950"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/327k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c459ac49294cbcaaeb994d1c524b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/80.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82982eee9cab434b89da6818e3fbf724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3877 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c701990118f44e39e4e32841442e66d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/969 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f5e42d0b75443d1bb8f13bd358da852"}},"metadata":{}},{"name":"stdout","text":"Dataset shape: (3877, 2)\n\nFirst few rows:\n                                            sentence  label\n0  Altia 's operating profit jumped to EUR 47 mil...      2\n1  The agreement was signed with Biohit Healthcar...      2\n2  Kesko pursues a strategy of healthy , focused ...      2\n3  Vaisala , headquartered in Helsinki in Finland...      1\n4  Also , a six-year historic analysis is provide...      1\n\nColumn names:\n['sentence', 'label']\n\nLabel distribution:\nlabel\n1    2320\n2    1077\n0     480\nName: count, dtype: int64\n\nLabel mapping:\n{0: 0, 1: 1, 2: 2}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Prepare train/test split\nX = df['sentence'].values\ny = df['label_numeric'].values\n\n# Get number of classes\nnum_classes = len(reverse_label_map)\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Classes: {list(reverse_label_map.values())}\")\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTraining samples: {len(X_train)}\")\nprint(f\"Testing samples: {len(X_test)}\")\nprint(f\"\\nTraining label distribution: {np.bincount(y_train)}\")\nprint(f\"Testing label distribution: {np.bincount(y_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:23:52.148678Z","iopub.execute_input":"2025-12-09T12:23:52.148904Z","iopub.status.idle":"2025-12-09T12:23:52.158633Z","shell.execute_reply.started":"2025-12-09T12:23:52.148884Z","shell.execute_reply":"2025-12-09T12:23:52.157972Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 3\nClasses: [0, 1, 2]\n\nTraining samples: 3101\nTesting samples: 776\n\nTraining label distribution: [ 384 1856  861]\nTesting label distribution: [ 96 464 216]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model_name = \"ProsusAI/finbert\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbert_model = AutoModel.from_pretrained(model_name)\n\n# Freeze BERT parameters\nfor param in bert_model.parameters():\n    param.requires_grad = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbert_model = bert_model.to(device)\nbert_model.eval()\n\nprint(f\"✓ BERT model loaded on {device}\")\nprint(f\"✓ Model parameters frozen\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:17.156481Z","iopub.execute_input":"2025-12-09T12:32:17.157105Z","iopub.status.idle":"2025-12-09T12:32:18.324699Z","shell.execute_reply.started":"2025-12-09T12:32:17.157076Z","shell.execute_reply":"2025-12-09T12:32:18.324069Z"}},"outputs":[{"name":"stdout","text":"✓ BERT model loaded on cuda\n✓ Model parameters frozen\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def get_bert_embeddings(texts, batch_size=16):\n    \"\"\"Extract BERT embeddings using [CLS] token\"\"\"\n    embeddings = []\n    \n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        \n        # Tokenize\n        encoded = tokenizer(\n            batch_texts,\n            padding=True,\n            truncation=True,\n            max_length=128,\n            return_tensors='pt'\n        )\n        \n        # Move to device\n        encoded = {k: v.to(device) for k, v in encoded.items()}\n        \n        # Get embeddings\n        with torch.no_grad():\n            outputs = bert_model(**encoded)\n            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n            embeddings.append(cls_embeddings.cpu().numpy())\n    \n    return np.vstack(embeddings)\n\nprint(\"✓ Embedding extraction function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:21.976745Z","iopub.execute_input":"2025-12-09T12:32:21.977032Z","iopub.status.idle":"2025-12-09T12:32:21.983503Z","shell.execute_reply.started":"2025-12-09T12:32:21.977011Z","shell.execute_reply":"2025-12-09T12:32:21.982741Z"}},"outputs":[{"name":"stdout","text":"✓ Embedding extraction function defined\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(\"Extracting embeddings for training data...\")\nX_train_embeddings = get_bert_embeddings(X_train.tolist())\nprint(f\"✓ Training embeddings shape: {X_train_embeddings.shape}\")\n\nprint(\"Extracting embeddings for test data...\")\nX_test_embeddings = get_bert_embeddings(X_test.tolist())\nprint(f\"✓ Test embeddings shape: {X_test_embeddings.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:22.226895Z","iopub.execute_input":"2025-12-09T12:32:22.227161Z","iopub.status.idle":"2025-12-09T12:32:35.797354Z","shell.execute_reply.started":"2025-12-09T12:32:22.227139Z","shell.execute_reply":"2025-12-09T12:32:35.796715Z"}},"outputs":[{"name":"stdout","text":"Extracting embeddings for training data...\n✓ Training embeddings shape: (3101, 768)\nExtracting embeddings for test data...\n✓ Test embeddings shape: (776, 768)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 1: BERT + Trainable Classification Head\")\nprint(\"=\"*70)\n\nclass BERTClassifier(nn.Module):\n    def __init__(self, hidden_size=768, num_classes=num_classes):\n        super(BERTClassifier, self).__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, embeddings):\n        return self.classifier(embeddings)\n\n# Initialize model\nclassifier_model = BERTClassifier(num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(classifier_model.parameters(), lr=0.001)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.FloatTensor(X_train_embeddings).to(device)\ny_train_tensor = torch.LongTensor(y_train).to(device)\nX_test_tensor = torch.FloatTensor(X_test_embeddings).to(device)\n\n# Training loop\nnum_epochs = 30\nbatch_size = 32\n\nprint(\"\\nTraining classification head...\")\nclassifier_model.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for i in range(0, len(X_train_tensor), batch_size):\n        batch_X = X_train_tensor[i:i+batch_size]\n        batch_y = y_train_tensor[i:i+batch_size]\n        \n        optimizer.zero_grad()\n        outputs = classifier_model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    if (epoch + 1) % 2 == 0:\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(X_train_tensor):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:35.79853Z","iopub.execute_input":"2025-12-09T12:32:35.798749Z","iopub.status.idle":"2025-12-09T12:32:39.520439Z","shell.execute_reply.started":"2025-12-09T12:32:35.798732Z","shell.execute_reply":"2025-12-09T12:32:39.519843Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 1: BERT + Trainable Classification Head\n======================================================================\n\nTraining classification head...\nEpoch [2/30], Loss: 0.0078\nEpoch [4/30], Loss: 0.0073\nEpoch [6/30], Loss: 0.0068\nEpoch [8/30], Loss: 0.0064\nEpoch [10/30], Loss: 0.0059\nEpoch [12/30], Loss: 0.0056\nEpoch [14/30], Loss: 0.0050\nEpoch [16/30], Loss: 0.0050\nEpoch [18/30], Loss: 0.0047\nEpoch [20/30], Loss: 0.0044\nEpoch [22/30], Loss: 0.0039\nEpoch [24/30], Loss: 0.0037\nEpoch [26/30], Loss: 0.0033\nEpoch [28/30], Loss: 0.0030\nEpoch [30/30], Loss: 0.0030\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Evaluation\nclassifier_model.eval()\nwith torch.no_grad():\n    outputs = classifier_model(X_test_tensor)\n    _, y_pred_approach1 = torch.max(outputs, 1)\n    y_pred_approach1 = y_pred_approach1.cpu().numpy()\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 1 - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_approach1, \n                         target_names=[str(v) for v in reverse_label_map.values()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:39.521012Z","iopub.execute_input":"2025-12-09T12:32:39.521185Z","iopub.status.idle":"2025-12-09T12:32:39.533396Z","shell.execute_reply.started":"2025-12-09T12:32:39.521171Z","shell.execute_reply":"2025-12-09T12:32:39.532465Z"}},"outputs":[{"name":"stdout","text":"\n----------------------------------------------------------------------\nAPPROACH 1 - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89        96\n           1       0.93      0.93      0.93       464\n           2       0.88      0.88      0.88       216\n\n    accuracy                           0.91       776\n   macro avg       0.90      0.90      0.90       776\nweighted avg       0.91      0.91      0.91       776\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2: BERT as Embedder + Logistic Regression\")\nprint(\"=\"*70)\n\n# Train Logistic Regression\nlr_classifier = LogisticRegression(max_iter=1000, random_state=42)\nprint(\"Training Logistic Regression classifier...\")\nlr_classifier.fit(X_train_embeddings, y_train)\n\n# Predictions\ny_pred_approach2 = lr_classifier.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2 - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_approach2, \n                          target_names=[str(v) for v in reverse_label_map.values()]))\n\n# ============================================================================\n# CELL 10: APPROACH 3 - BERT + Cosine Similarity Classification\n# ============================================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 3: BERT + Cosine Similarity Classification\")\nprint(\"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:39.534913Z","iopub.execute_input":"2025-12-09T12:32:39.535086Z","iopub.status.idle":"2025-12-09T12:32:43.945295Z","shell.execute_reply.started":"2025-12-09T12:32:39.535071Z","shell.execute_reply":"2025-12-09T12:32:43.944667Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2: BERT as Embedder + Logistic Regression\n======================================================================\nTraining Logistic Regression classifier...\n\n----------------------------------------------------------------------\nAPPROACH 2 - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89        96\n           1       0.92      0.92      0.92       464\n           2       0.86      0.86      0.86       216\n\n    accuracy                           0.90       776\n   macro avg       0.89      0.89      0.89       776\nweighted avg       0.90      0.90      0.90       776\n\n\n======================================================================\nAPPROACH 3: BERT + Cosine Similarity Classification\n======================================================================\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2B: BERT + SVM Classifier\")\nprint(\"=\"*70)\n\nsvm_clf = SVC(kernel='linear', probability=True, random_state=42)\n\nprint(\"Training SVM classifier...\")\nsvm_clf.fit(X_train_embeddings, y_train)\n\ny_pred_svm = svm_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2B - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_svm, \n                            target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:47.165113Z","iopub.execute_input":"2025-12-09T12:32:47.16581Z","iopub.status.idle":"2025-12-09T12:32:52.407266Z","shell.execute_reply.started":"2025-12-09T12:32:47.165782Z","shell.execute_reply":"2025-12-09T12:32:52.406521Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2B: BERT + SVM Classifier\n======================================================================\nTraining SVM classifier...\n\n----------------------------------------------------------------------\nAPPROACH 2B - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87        96\n           1       0.91      0.90      0.91       464\n           2       0.83      0.86      0.84       216\n\n    accuracy                           0.88       776\n   macro avg       0.87      0.87      0.87       776\nweighted avg       0.88      0.88      0.88       776\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2F: BERT + MLP Neural Network\")\nprint(\"=\"*70)\n\nmlp_clf = MLPClassifier(\n    hidden_layer_sizes=(512, 256, 128),\n    activation='relu',\n    solver='adam',\n    max_iter=50,\n    random_state=42\n)\n\nprint(\"Training MLP classifier...\")\nmlp_clf.fit(X_train_embeddings, y_train)\n\ny_pred_mlp = mlp_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2F - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_mlp,\n                            target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:32:58.062751Z","iopub.execute_input":"2025-12-09T12:32:58.063046Z","iopub.status.idle":"2025-12-09T12:33:06.181533Z","shell.execute_reply.started":"2025-12-09T12:32:58.063027Z","shell.execute_reply":"2025-12-09T12:33:06.180753Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2F: BERT + MLP Neural Network\n======================================================================\nTraining MLP classifier...\n\n----------------------------------------------------------------------\nAPPROACH 2F - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87        96\n           1       0.91      0.93      0.92       464\n           2       0.87      0.85      0.86       216\n\n    accuracy                           0.90       776\n   macro avg       0.89      0.88      0.88       776\nweighted avg       0.90      0.90      0.90       776\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2G: BERT + KNN\")\nprint(\"=\"*70)\n\nknn_clf = KNeighborsClassifier(n_neighbors=5)\n\nprint(\"Training KNN classifier...\")\nknn_clf.fit(X_train_embeddings, y_train)\n\ny_pred_knn = knn_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2G - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_knn, \n                             target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:26:00.504237Z","iopub.execute_input":"2025-12-09T12:26:00.504516Z","iopub.status.idle":"2025-12-09T12:26:00.771897Z","shell.execute_reply.started":"2025-12-09T12:26:00.504495Z","shell.execute_reply":"2025-12-09T12:26:00.77115Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2G: BERT + KNN\n======================================================================\nTraining KNN classifier...\n\n----------------------------------------------------------------------\nAPPROACH 2G - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.84      0.94      0.89        96\n           1       0.93      0.92      0.93       464\n           2       0.88      0.87      0.88       216\n\n    accuracy                           0.91       776\n   macro avg       0.89      0.91      0.90       776\nweighted avg       0.91      0.91      0.91       776\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2H: BERT + Gaussian Naive Bayes\")\nprint(\"=\"*70)\n\nnb_clf = GaussianNB()\nnb_clf.fit(X_train_embeddings, y_train)\n\ny_pred_nb = nb_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2H - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_nb,\n                            target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:26:03.0562Z","iopub.execute_input":"2025-12-09T12:26:03.056823Z","iopub.status.idle":"2025-12-09T12:26:03.113702Z","shell.execute_reply.started":"2025-12-09T12:26:03.056798Z","shell.execute_reply":"2025-12-09T12:26:03.112982Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2H: BERT + Gaussian Naive Bayes\n======================================================================\n\n----------------------------------------------------------------------\nAPPROACH 2H - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.81      0.96      0.88        96\n           1       0.94      0.91      0.92       464\n           2       0.88      0.88      0.88       216\n\n    accuracy                           0.91       776\n   macro avg       0.88      0.92      0.89       776\nweighted avg       0.91      0.91      0.91       776\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2I: BERT + CatBoost\")\nprint(\"=\"*70)\n\ncb_clf = CatBoostClassifier(\n    iterations=300,\n    learning_rate=0.05,\n    depth=6,\n    loss_function='MultiClass',\n    verbose=False\n)\n\ncb_clf.fit(X_train_embeddings, y_train)\n\ny_pred_cb = cb_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2I - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_cb, \n                            target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:26:06.611144Z","iopub.execute_input":"2025-12-09T12:26:06.611795Z","iopub.status.idle":"2025-12-09T12:27:17.279493Z","shell.execute_reply.started":"2025-12-09T12:26:06.611772Z","shell.execute_reply":"2025-12-09T12:27:17.278732Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2I: BERT + CatBoost\n======================================================================\n\n----------------------------------------------------------------------\nAPPROACH 2I - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.88      0.94      0.91        96\n           1       0.94      0.93      0.94       464\n           2       0.89      0.87      0.88       216\n\n    accuracy                           0.92       776\n   macro avg       0.90      0.91      0.91       776\nweighted avg       0.92      0.92      0.92       776\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROACH 2D: BERT + Random Forest\")\nprint(\"=\"*70)\n\n# Create Random Forest model\nrf_clf = RandomForestClassifier(\n    n_estimators=300,      # number of trees\n    max_depth=None,       # let trees grow fully\n    random_state=42,\n    n_jobs=-1             # parallel processing\n)\n\nprint(\"Training Random Forest classifier...\")\nrf_clf.fit(X_train_embeddings, y_train)\n\n# Predictions\ny_pred_rf = rf_clf.predict(X_test_embeddings)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 2D - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(\n    y_test, \n    y_pred_rf, \n    target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:27:17.280936Z","iopub.execute_input":"2025-12-09T12:27:17.281218Z","iopub.status.idle":"2025-12-09T12:27:27.558055Z","shell.execute_reply.started":"2025-12-09T12:27:17.2812Z","shell.execute_reply":"2025-12-09T12:27:27.557394Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAPPROACH 2D: BERT + Random Forest\n======================================================================\nTraining Random Forest classifier...\n\n----------------------------------------------------------------------\nAPPROACH 2D - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89        96\n           1       0.92      0.94      0.93       464\n           2       0.89      0.85      0.87       216\n\n    accuracy                           0.91       776\n   macro avg       0.90      0.89      0.89       776\nweighted avg       0.91      0.91      0.91       776\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Define label descriptions for auditor reviews\n# Adjust these based on what the actual labels are in the dataset\nlabel_descriptions = {}\nfor idx, label in reverse_label_map.items():\n    label_descriptions[idx] = f\"This is an auditor review with {label} sentiment or classification\"\n\nprint(\"Label descriptions:\")\nfor idx, desc in label_descriptions.items():\n    print(f\"  {idx} ({reverse_label_map[idx]}): {desc}\")\n\n# Get embeddings for label descriptions\nprint(\"\\nExtracting label description embeddings...\")\nlabel_texts = [label_descriptions[i] for i in range(num_classes)]\nlabel_embeddings = get_bert_embeddings(label_texts)\n\nprint(f\"Label embeddings shape: {label_embeddings.shape}\")\n\n# Predict using cosine similarity\nprint(\"Computing cosine similarities...\")\nsimilarities = cosine_similarity(X_test_embeddings, label_embeddings)\ny_pred_approach3 = np.argmax(similarities, axis=1)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"APPROACH 3 - Classification Report:\")\nprint(\"-\"*70)\nprint(classification_report(y_test, y_pred_approach3, \n                           target_names=[str(v) for v in reverse_label_map.values()]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:27:27.558959Z","iopub.execute_input":"2025-12-09T12:27:27.559344Z","iopub.status.idle":"2025-12-09T12:27:27.591468Z","shell.execute_reply.started":"2025-12-09T12:27:27.559316Z","shell.execute_reply":"2025-12-09T12:27:27.590783Z"}},"outputs":[{"name":"stdout","text":"Label descriptions:\n  0 (0): This is an auditor review with 0 sentiment or classification\n  1 (1): This is an auditor review with 1 sentiment or classification\n  2 (2): This is an auditor review with 2 sentiment or classification\n\nExtracting label description embeddings...\nLabel embeddings shape: (3, 768)\nComputing cosine similarities...\n\n----------------------------------------------------------------------\nAPPROACH 3 - Classification Report:\n----------------------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.70      0.99      0.82        96\n           1       0.96      0.67      0.79       464\n           2       0.61      0.90      0.73       216\n\n    accuracy                           0.77       776\n   macro avg       0.76      0.85      0.78       776\nweighted avg       0.83      0.77      0.77       776\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"COMPARISON OF ALL THREE APPROACHES\")\nprint(\"=\"*70)\n\napproaches = {\n    'Approach 1 (BERT + Classification Head)': y_pred_approach1,\n    'Approach 2 (BERT + Logistic Regression)': y_pred_approach2,\n    'Approach 3 (BERT + Cosine Similarity)': y_pred_approach3\n}\n\nresults_summary = []\nfor name, predictions in approaches.items():\n    acc = accuracy_score(y_test, predictions)\n    results_summary.append({'Approach': name, 'Accuracy': acc})\n    print(f\"{name}: {acc:.4f}\")\n\nresults_df = pd.DataFrame(results_summary)\nprint(\"\\n\" + \"-\"*70)\nprint(\"Summary Table:\")\nprint(\"-\"*70)\nprint(results_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T12:27:27.592691Z","iopub.execute_input":"2025-12-09T12:27:27.59289Z","iopub.status.idle":"2025-12-09T12:27:27.603481Z","shell.execute_reply.started":"2025-12-09T12:27:27.592874Z","shell.execute_reply":"2025-12-09T12:27:27.602653Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nCOMPARISON OF ALL THREE APPROACHES\n======================================================================\nApproach 1 (BERT + Classification Head): 0.9034\nApproach 2 (BERT + Logistic Regression): 0.8982\nApproach 3 (BERT + Cosine Similarity): 0.7706\n\n----------------------------------------------------------------------\nSummary Table:\n----------------------------------------------------------------------\n                               Approach  Accuracy\nApproach 1 (BERT + Classification Head)  0.903351\nApproach 2 (BERT + Logistic Regression)  0.898196\n  Approach 3 (BERT + Cosine Similarity)  0.770619\n","output_type":"stream"}],"execution_count":19}]}